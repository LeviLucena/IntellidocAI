<p align="center">

  <!-- Linguagem principal -->
  <a href="https://www.python.org/">
    <img src="https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white" alt="Python" />
  </a>

  <!-- Frameworks Web -->
  <a href="https://flask.palletsprojects.com/">
    <img src="https://img.shields.io/badge/-Flask-000000?style=flat-square&logo=flask&logoColor=white" alt="Flask" />
  </a>
  <a href="https://dash.plotly.com/">
    <img src="https://img.shields.io/badge/-Dash-1E1E1E?style=flat-square&logo=plotly&logoColor=white" alt="Dash" />
  </a>

  <!-- IA / LLMs -->
  <a href="https://platform.openai.com/">
    <img src="https://img.shields.io/badge/-OpenAI-412991?style=flat-square&logo=openai&logoColor=white" alt="OpenAI API" />
  </a>

  <!-- NLP e VetorizaÃ§Ã£o -->
  <a href="https://scikit-learn.org/">
    <img src="https://img.shields.io/badge/-Scikit--Learn-F7931E?style=flat-square&logo=scikit-learn&logoColor=white" alt="Scikit-learn" />
  </a>
  <a href="https://numpy.org/">
    <img src="https://img.shields.io/badge/-NumPy-013243?style=flat-square&logo=numpy&logoColor=white" alt="NumPy" />
  </a>
  <a href="https://github.com/facebookresearch/faiss">
    <img src="https://img.shields.io/badge/-FAISS-005571?style=flat-square&logo=facebook&logoColor=white" alt="FAISS" />
  </a>

  <!-- OCR e VisÃ£o Computacional -->
  <a href="https://pypi.org/project/pytesseract/">
    <img src="https://img.shields.io/badge/-Tesseract%20OCR-5A4FCF?style=flat-square&logo=tesseract&logoColor=white" alt="Tesseract OCR" />
  </a>
  <a href="https://pillow.readthedocs.io/">
    <img src="https://img.shields.io/badge/-Pillow-7A4F87?style=flat-square&logo=python&logoColor=white" alt="Pillow" />
  </a>
  <a href="https://github.com/ultralytics/ultralytics">
    <img src="https://img.shields.io/badge/-YOLOv8-00FFFF?style=flat-square&logo=github&logoColor=black" alt="YOLOv8 Ultralytics" />
  </a>
  <a href="https://opencv.org/">
    <img src="https://img.shields.io/badge/-OpenCV-5C3EE8?style=flat-square&logo=opencv&logoColor=white" alt="OpenCV" />
  </a>

  <!-- Leitura de PDFs -->
  <a href="https://pymupdf.readthedocs.io/">
    <img src="https://img.shields.io/badge/-PyMuPDF-005F6A?style=flat-square&logo=readthedocs&logoColor=white" alt="PyMuPDF" />
  </a>

  <!-- ManipulaÃ§Ã£o e Requests -->
  <a href="https://pandas.pydata.org/">
    <img src="https://img.shields.io/badge/-Pandas-150458?style=flat-square&logo=pandas&logoColor=white" alt="Pandas" />
  </a>
  <a href="https://requests.readthedocs.io/">
    <img src="https://img.shields.io/badge/-Requests-20232A?style=flat-square&logo=python&logoColor=white" alt="Requests" />
  </a>

  <!-- VariÃ¡veis de Ambiente -->
  <a href="https://pypi.org/project/python-dotenv/">
    <img src="https://img.shields.io/badge/-Dotenv-ECD53F?style=flat-square&logo=python&logoColor=black" alt="Dotenv" />
  </a>

  <!-- Servidor de ProduÃ§Ã£o -->
  <a href="https://gunicorn.org/">
    <img src="https://img.shields.io/badge/-Gunicorn-499848?style=flat-square&logo=linux&logoColor=white" alt="Gunicorn" />
  </a>

  <!-- Status do projeto -->
  <img src="https://img.shields.io/badge/status-em%20desenvolvimento-yellow?style=flat-square" alt="Status" />

  <!-- LicenÃ§a -->
  <img src="https://img.shields.io/badge/license-MIT-blue?style=flat-square" alt="MIT License" />

</p>

![image](https://github.com/user-attachments/assets/c14e3353-47cb-44d3-82f8-da2936298937)

# ğŸ§  IntelliDoc AI - AnÃ¡lise Inteligente de Documentos com OCR, RAG e VisÃ£o Computacional
**IntelliDoc AI** Ã© um sistema web inteligente construÃ­do em Python que realiza **anÃ¡lise automatizada de documentos** em PDF, combinando tÃ©cnicas de **OCR, RAG (Retrieval-Augmented Generation)** e **detecÃ§Ã£o visual com YOLOv8**. A interface web interativa Ã© construÃ­da com **Dash** e roda sobre um backend **Flask**, integrando processamento de linguagem natural, visÃ£o computacional e modelos generativos.

---

## ğŸš€ Funcionalidades

- ğŸ“„ **Upload de documentos PDF**
- ğŸ” **ExtraÃ§Ã£o de texto (OCR) com PyMuPDF e pytesseract**
- ğŸ¯ **DetecÃ§Ã£o visual com YOLOv8 (Ultralytics + OpenCV)**
- â“ **Perguntas e respostas com RAG + OpenAI (embeddings + LLM)**
- ğŸ–¼ï¸ **VisualizaÃ§Ã£o de imagens com marcaÃ§Ãµes dos objetos detectados**
- ğŸŒ Interface responsiva com Dash + Bootstrap

## ğŸ§ª Exemplo de Uso
- FaÃ§a upload de um PDF (ex: contrato, fatura, laudo tÃ©cnico).
- Extraia o texto com OCR automaticamente.
- Ative a opÃ§Ã£o â€œRodar YOLOâ€ para identificar elementos visuais (selos, logos, carimbos, assinaturas etc.).
- Digite uma pergunta sobre o conteÃºdo do documento.
- Veja a resposta gerada com base nos trechos mais relevantes.

https://github.com/user-attachments/assets/9228f762-07f9-482a-a931-d3042f04d5f5

---

## ğŸ§° Tecnologias Utilizadas

| Ãrea                     | Ferramentas / Bibliotecas                                                  |
|--------------------------|----------------------------------------------------------------------------|
| **Interface Web**        | [Dash](https://dash.plotly.com/), [Flask](https://flask.palletsprojects.com/) |
| **OCR**                  | [PyMuPDF](https://pymupdf.readthedocs.io/), [pytesseract](https://github.com/madmaze/pytesseract), [Pillow](https://python-pillow.org/) |
| **VisÃ£o Computacional**  | [YOLOv8 (Ultralytics)](https://docs.ultralytics.com/), [OpenCV](https://opencv.org/) |
| **RAG & NLP**            | [OpenAI API](https://platform.openai.com/), [NumPy](https://numpy.org/), [scikit-learn](https://scikit-learn.org/), [faiss-cpu](https://github.com/facebookresearch/faiss) |
| **Ambiente e Servidor**  | [python-dotenv](https://pypi.org/project/python-dotenv/), [gunicorn](https://gunicorn.org/), [requests](https://requests.readthedocs.io/en/latest/) |
| **Outros**               | [pandas](https://pandas.pydata.org/) (opcional para relatÃ³rios futuros) |

## ğŸ§  Futuras Melhorias
- Armazenamento vetorial com FAISS + persistÃªncia
- IntegraÃ§Ã£o com banco de dados (PostgreSQL ou SQLite)
- Dashboard de relatÃ³rios com pandas + Plotly
- Suporte a mÃºltiplos arquivos e histÃ³rico de perguntas
- Deploy no Hugging Face Spaces ou AWS/GCP

---

## ğŸ“ Estrutura do Projeto
```bash
intellidoc/
â”œâ”€â”€ app/                          # MÃ³dulos de backend e processamento (OCR, RAG, YOLO, embeddings, etc.)
â”‚   â”œâ”€â”€ __init__.py              # Inicializador do pacote app (pode estar vazio)
â”‚   â”œâ”€â”€ ocr.py                   # MÃ³dulo de OCR: extrai texto de PDFs usando PyMuPDF e pytesseract
â”‚   â”œâ”€â”€ rag.py                   # MÃ³dulo de RAG: recuperaÃ§Ã£o + geraÃ§Ã£o com embeddings e OpenAI
â”‚   â”œâ”€â”€ yolo_detector.py         # MÃ³dulo de detecÃ§Ã£o visual com YOLO (Ultralytics + OpenCV)
â”‚   â”œâ”€â”€ embeddings.py            # GeraÃ§Ã£o de embeddings com API OpenAI (modelo text-embedding-3)
â”‚   â”œâ”€â”€ utils.py                 # FunÃ§Ãµes auxiliares diversas (opcional)
â”‚
â”œâ”€â”€ assets/                      # Pasta padrÃ£o do Dash para assets estÃ¡ticos (imagens, CSS, etc.)
â”‚   â””â”€â”€ logo.png                 # Logotipo exibido na interface (usado com `html.Img`)
â”‚
â”œâ”€â”€ dash_app.py                  # Arquivo principal da aplicaÃ§Ã£o com layout e callbacks do Dash
â”‚                                # Integra os mÃ³dulos de OCR, RAG e YOLO e define a interface do usuÃ¡rio
â”‚
â”œâ”€â”€ config.py                    # ConfiguraÃ§Ã£o global (ex.: leitura de variÃ¡veis de ambiente)
â”‚                                # Inclui sua chave da OpenAI e outras configuraÃ§Ãµes
â”‚
â”œâ”€â”€ requirements.txt             # Lista de dependÃªncias para instalar o ambiente (pip install -r)
â”‚
â”œâ”€â”€ run.py                       # Arquivo de execuÃ§Ã£o para produÃ§Ã£o (ex: via gunicorn)
â”‚                                # Pode simplesmente fazer `from dash_app import server`
```

## ğŸ› ï¸ Como Executar o Projeto Localmente

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/LeviLucena/IntellidocAI.git
cd intellidoc
```

### 2. Crie um ambiente virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Configure as variÃ¡veis de ambiente
Crie um arquivo .env na raiz com o seguinte conteÃºdo:

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

### 5. Execute o app (modo desenvolvimento)

```bash
python run.py
```

Acesse o app em: http://localhost:8050

### 6. Executar em produÃ§Ã£o (via gunicorn)

```bash
gunicorn run:server
```

## ğŸ“š ReferÃªncias

- OpenAI Python SDK (v1.x): https://github.com/openai/openai-python
- YOLOv8 by Ultralytics: https://docs.ultralytics.com/
- Dash Docs: https://dash.plotly.com/
- pytesseract OCR: https://github.com/madmaze/pytesseract
- PyMuPDF: https://pymupdf.readthedocs.io/
- scikit-learn (cosine_similarity): https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html
- FAISS Search: https://github.com/facebookresearch/faiss
- RAG Paper: https://arxiv.org/abs/2005.11401

- ## ğŸ¤ Como Contribuir
Sinta-se Ã  vontade para contribuir, sugerir melhorias ou relatar problemas para ajudar a desenvolver este projeto.

## ğŸ“„ LicenÃ§a
Este projeto estÃ¡ licenciado sob a licenÃ§a MIT â€” veja [LICENSE](https://github.com/github/gitignore/blob/main/LICENSE) para detalhes.
